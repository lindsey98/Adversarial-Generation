{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faster-RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../detectron2_1/')\n",
    "\n",
    "import detectron2_1\n",
    "from detectron2.config import get_cfg\n",
    "from pathlib import Path\n",
    "from detectron2.engine import DefaultPredictor\n",
    "import cv2\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.modeling import build_model\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "An object named 'QuantizeRPNHead' was already registered in 'RPN_HEAD' registry!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-37392a418ba3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mRPN_HEAD_REGISTRY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mQuantizeRPNHead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \"\"\"\n\u001b[1;32m     25\u001b[0m     \u001b[0mStandard\u001b[0m \u001b[0mRPN\u001b[0m \u001b[0mclassification\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mregression\u001b[0m \u001b[0mheads\u001b[0m \u001b[0mdescribed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mpaper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mFaster\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mCNN\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mypy37/lib/python3.7/site-packages/fvcore/common/registry.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(func_or_class)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_or_class\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_or_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m  \u001b[0;31m# pyre-ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_register\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_or_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_or_class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mypy37/lib/python3.7/site-packages/fvcore/common/registry.py\u001b[0m in \u001b[0;36m_do_register\u001b[0;34m(self, name, obj)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_obj_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"An object named '{}' was already registered in '{}' registry!\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         )\n\u001b[1;32m     46\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_obj_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: An object named 'QuantizeRPNHead' was already registered in 'RPN_HEAD' registry!"
     ]
    }
   ],
   "source": [
    "from detectron2.modeling import RPN_HEAD_REGISTRY, Backbone, ShapeSpec\n",
    "from detectron2.modeling.anchor_generator import build_anchor_generator\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from detectron2.config import configurable\n",
    "\n",
    "class QuantizeRelu(nn.Module):\n",
    "    def __init__(self, step_size = 0.01):\n",
    "        super().__init__()\n",
    "        self.step_size = step_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        mask = torch.ge(x, 0).bool() # mask for positive values\n",
    "        quantize = torch.ones_like(x) * self.step_size\n",
    "        out = torch.mul(torch.floor(torch.div(x, quantize)), self.step_size) # quantize by step_size\n",
    "        out = torch.mul(out, mask) # zero-out negative values\n",
    "        out = torch.abs(out) # remove sign\n",
    "        return out\n",
    "\n",
    "@RPN_HEAD_REGISTRY.register()\n",
    "class QuantizeRPNHead(nn.Module):\n",
    "    \"\"\"\n",
    "    Standard RPN classification and regression heads described in :paper:`Faster R-CNN`.\n",
    "    Uses a 3x3 conv to produce a shared hidden state from which one 1x1 conv predicts\n",
    "    objectness logits for each anchor and a second 1x1 conv predicts bounding-box deltas\n",
    "    specifying how to deform each anchor into an object proposal.\n",
    "    \"\"\"\n",
    "\n",
    "    @configurable\n",
    "    def __init__(self, *, in_channels: int, num_anchors: int, box_dim: int = 4):\n",
    "        \"\"\"\n",
    "        NOTE: this interface is experimental.\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): number of input feature channels. When using multiple\n",
    "                input features, they must have the same number of channels.\n",
    "            num_anchors (int): number of anchors to predict for *each spatial position*\n",
    "                on the feature map. The total number of anchors for each\n",
    "                feature map will be `num_anchors * H * W`.\n",
    "            box_dim (int): dimension of a box, which is also the number of box regression\n",
    "                predictions to make for each anchor. An axis aligned box has\n",
    "                box_dim=4, while a rotated box has box_dim=5.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # 3x3 conv for the hidden representation\n",
    "        self.conv = nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1)\n",
    "        # 1x1 conv for predicting objectness logits\n",
    "        self.objectness_logits = nn.Conv2d(in_channels, num_anchors, kernel_size=1, stride=1)\n",
    "        # 1x1 conv for predicting box2box transform deltas\n",
    "        self.anchor_deltas = nn.Conv2d(in_channels, num_anchors * box_dim, kernel_size=1, stride=1)\n",
    "\n",
    "        for l in [self.conv, self.objectness_logits, self.anchor_deltas]:\n",
    "            nn.init.normal_(l.weight, std=0.01)\n",
    "            nn.init.constant_(l.bias, 0)\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, cfg, input_shape):\n",
    "        # Standard RPN is shared across levels:\n",
    "        in_channels = [s.channels for s in input_shape]\n",
    "        assert len(set(in_channels)) == 1, \"Each level must have the same channel!\"\n",
    "        in_channels = in_channels[0]\n",
    "\n",
    "        # RPNHead should take the same input as anchor generator\n",
    "        # NOTE: it assumes that creating an anchor generator does not have unwanted side effect.\n",
    "        anchor_generator = build_anchor_generator(cfg, input_shape)\n",
    "        num_anchors = anchor_generator.num_anchors\n",
    "        box_dim = anchor_generator.box_dim\n",
    "        assert (\n",
    "            len(set(num_anchors)) == 1\n",
    "        ), \"Each level must have the same number of anchors per spatial position\"\n",
    "        return {\"in_channels\": in_channels, \"num_anchors\": num_anchors[0], \"box_dim\": box_dim}\n",
    "\n",
    "    def forward(self, features: List[torch.Tensor]):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            features (list[Tensor]): list of feature maps\n",
    "\n",
    "        Returns:\n",
    "            list[Tensor]: A list of L elements.\n",
    "                Element i is a tensor of shape (N, A, Hi, Wi) representing\n",
    "                the predicted objectness logits for all anchors. A is the number of cell anchors.\n",
    "            list[Tensor]: A list of L elements. Element i is a tensor of shape\n",
    "                (N, A*box_dim, Hi, Wi) representing the predicted \"deltas\" used to transform anchors\n",
    "                to proposals.\n",
    "        \"\"\"\n",
    "        pred_objectness_logits = []\n",
    "        pred_anchor_deltas = []\n",
    "        for x in features:\n",
    "            t = QuantizeRelu(self.conv(x))\n",
    "            pred_objectness_logits.append(self.objectness_logits(t))\n",
    "            pred_anchor_deltas.append(self.anchor_deltas(t))\n",
    "        return pred_objectness_logits, pred_anchor_deltas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_path = 'configs/faster_rcnn_bet365.yaml'\n",
    "weights_path = 'output/rcnn_2/rcnn_bet365.pth'\n",
    "conf_threshold = 0.05\n",
    "iou_low_threshold = 0.5\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(cfg_path)\n",
    "cfg.MODEL.WEIGHTS = weights_path\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = conf_threshold\n",
    "cfg.MODEL.RPN.HEAD_NAME = 'QuantizeRPNHead'\n",
    "\n",
    "model = build_model(cfg)  # returns a torch.nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GeneralizedRCNN(\n",
       "  (backbone): FPN(\n",
       "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (top_block): LastLevelMaxPool()\n",
       "    (bottom_up): ResNet(\n",
       "      (stem): BasicStem(\n",
       "        (conv1): Conv2d(\n",
       "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
       "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
       "        )\n",
       "      )\n",
       "      (res2): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (shortcut): Conv2d(\n",
       "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
       "          )\n",
       "          (conv1): Conv2d(\n",
       "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
       "          )\n",
       "          (conv2): Conv2d(\n",
       "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
       "          )\n",
       "          (conv3): Conv2d(\n",
       "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (conv1): Conv2d(\n",
       "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
       "          )\n",
       "          (conv2): Conv2d(\n",
       "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
       "          )\n",
       "          (conv3): Conv2d(\n",
       "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (conv1): Conv2d(\n",
       "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
       "          )\n",
       "          (conv2): Conv2d(\n",
       "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
       "          )\n",
       "          (conv3): Conv2d(\n",
       "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (res3): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (shortcut): Conv2d(\n",
       "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
       "          )\n",
       "          (conv1): Conv2d(\n",
       "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
       "          )\n",
       "          (conv2): Conv2d(\n",
       "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
       "          )\n",
       "          (conv3): Conv2d(\n",
       "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (conv1): Conv2d(\n",
       "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
       "          )\n",
       "          (conv2): Conv2d(\n",
       "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
       "          )\n",
       "          (conv3): Conv2d(\n",
       "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (conv1): Conv2d(\n",
       "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
       "          )\n",
       "          (conv2): Conv2d(\n",
       "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
       "          )\n",
       "          (conv3): Conv2d(\n",
       "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (conv1): Conv2d(\n",
       "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
       "          )\n",
       "          (conv2): Conv2d(\n",
       "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
       "          )\n",
       "          (conv3): Conv2d(\n",
       "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (res4): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (shortcut): Conv2d(\n",
       "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
       "          )\n",
       "          (conv1): Conv2d(\n",
       "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
       "          )\n",
       "          (conv2): Conv2d(\n",
       "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
       "          )\n",
       "          (conv3): Conv2d(\n",
       "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (conv1): Conv2d(\n",
       "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
       "          )\n",
       "          (conv2): Conv2d(\n",
       "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
       "          )\n",
       "          (conv3): Conv2d(\n",
       "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (conv1): Conv2d(\n",
       "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
       "          )\n",
       "          (conv2): Conv2d(\n",
       "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
       "          )\n",
       "          (conv3): Conv2d(\n",
       "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (conv1): Conv2d(\n",
       "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
       "          )\n",
       "          (conv2): Conv2d(\n",
       "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
       "          )\n",
       "          (conv3): Conv2d(\n",
       "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (conv1): Conv2d(\n",
       "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
       "          )\n",
       "          (conv2): Conv2d(\n",
       "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
       "          )\n",
       "          (conv3): Conv2d(\n",
       "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (conv1): Conv2d(\n",
       "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
       "          )\n",
       "          (conv2): Conv2d(\n",
       "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
       "          )\n",
       "          (conv3): Conv2d(\n",
       "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (res5): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (shortcut): Conv2d(\n",
       "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
       "          )\n",
       "          (conv1): Conv2d(\n",
       "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
       "          )\n",
       "          (conv2): Conv2d(\n",
       "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
       "          )\n",
       "          (conv3): Conv2d(\n",
       "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (conv1): Conv2d(\n",
       "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
       "          )\n",
       "          (conv2): Conv2d(\n",
       "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
       "          )\n",
       "          (conv3): Conv2d(\n",
       "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (conv1): Conv2d(\n",
       "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
       "          )\n",
       "          (conv2): Conv2d(\n",
       "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
       "          )\n",
       "          (conv3): Conv2d(\n",
       "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (proposal_generator): RPN(\n",
       "    (rpn_head): QuantizeRPNHead(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (anchor_generator): DefaultAnchorGenerator(\n",
       "      (cell_anchors): BufferList()\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): StandardROIHeads(\n",
       "    (box_pooler): ROIPooler(\n",
       "      (level_poolers): ModuleList(\n",
       "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
       "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
       "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
       "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
       "      )\n",
       "    )\n",
       "    (box_head): FastRCNNConvFCHead(\n",
       "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNOutputLayers(\n",
       "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Siamese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../phishpedia/')\n",
    "from siamese.model_resnetv2 import *\n",
    "import torch.utils.data as data\n",
    "from PIL import Image, ImageOps\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dataloader \n",
    "class GetLoader(data.Dataset):\n",
    "    def __init__(self, data_root, data_list, label_dict, transform=None, grayscale=False):\n",
    "        self.transform = transform\n",
    "        self.data_root = data_root\n",
    "        self.grayscale = grayscale\n",
    "        \n",
    "        data_list = [x.strip() for x in open(data_list).readlines()]\n",
    "\n",
    "        with open(label_dict, 'rb') as handle:\n",
    "            self.label_dict = pickle.load(handle)\n",
    "\n",
    "        self.classes = list(self.label_dict.keys())\n",
    "\n",
    "\n",
    "        self.img_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        for data in data_list:\n",
    "            if os.path.exists(os.path.join(data_root, data)):\n",
    "                label = data.split('/')[0]\n",
    "                self.img_paths.append(data)\n",
    "                self.labels.append(label)\n",
    "                \n",
    "        self.n_data = len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "\n",
    "     #   print(self.data_root)\n",
    "        img_path, label= self.img_paths[item], self.labels[item]\n",
    "        #img_path_full = os.path.join(self.data_root, img_path)\n",
    "        img_path_full = os.path.join(self.data_root, img_path)\n",
    "        if self.grayscale:\n",
    "            img = Image.open(img_path_full).convert('L').convert('RGB')\n",
    "        else:\n",
    "            img = Image.open(img_path_full).convert('RGB')\n",
    "\n",
    "        img = ImageOps.expand(img, (\n",
    "            (max(img.size) - img.size[0]) // 2, (max(img.size) - img.size[1]) // 2,\n",
    "            (max(img.size) - img.size[0]) // 2, (max(img.size) - img.size[1]) // 2), fill=(255, 255, 255))\n",
    "        img = img.resize((128, 128))\n",
    "\n",
    "        # label = np.array(label,dtype='float32')\n",
    "        label = self.label_dict[label]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.5, 0.5, 0.5]\n",
    "std = [0.5, 0.5, 0.5]\n",
    "\n",
    "img_transforms = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=mean, std=std),\n",
    "    ])\n",
    "\n",
    "valid_set = GetLoader(data_root='/home/l/liny/ruofan/phishpedia/benchmark/targetlist_fit', \n",
    "                    data_list='/home/l/liny/ruofan/phishpedia/benchmark/targetlist_test-2.txt', \n",
    "                    label_dict='/home/l/liny/ruofan/phishpedia/benchmark/targetlist_labeldict.pkl',\n",
    "                     transform=img_transforms)\n",
    "\n",
    "train_set = GetLoader(data_root='/home/l/liny/ruofan/phishpedia/benchmark/targetlist_fit', \n",
    "                    data_list='/home/l/liny/ruofan/phishpedia/benchmark/targetlist_train-2.txt', \n",
    "                    label_dict='/home/l/liny/ruofan/phishpedia/benchmark/targetlist_labeldict.pkl',\n",
    "                     transform=img_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  train_set, batch_size=64, shuffle=False, pin_memory=True, drop_last=False)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "  valid_set, batch_size=1, shuffle=False, pin_memory=True, drop_last=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "461"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compute_acc(dataloader, model, device):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for b, (x, y) in enumerate(dataloader):\n",
    "        with torch.no_grad():\n",
    "            x = x.to(device, non_blocking=True)\n",
    "            y = y.to(device, non_blocking=True)\n",
    "            logits = model(x)\n",
    "            pred_cls = torch.argmax(logits, dim=1)\n",
    "\n",
    "            correct += torch.sum(torch.eq(pred_cls, y)).item()\n",
    "            total += y.shape[0]\n",
    "            \n",
    "    print('Accuracy after changing relu function: {:.2f}'.format(correct/total))    \n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load model (original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetV2(\n",
       "  (root): Sequential(\n",
       "    (conv): StdConv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (pad): ConstantPad2d(padding=(1, 1, 1, 1), value=0)\n",
       "    (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (body): Sequential(\n",
       "    (block1): Sequential(\n",
       "      (unit01): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (unit02): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit03): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (block2): Sequential(\n",
       "      (unit01): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): StdConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "      (unit02): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit03): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit04): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (block3): Sequential(\n",
       "      (unit01): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): StdConv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "      (unit02): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit03): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit04): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit05): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit06): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (block4): Sequential(\n",
       "      (unit01): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): StdConv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "      (unit02): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 2048, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit03): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 2048, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (gn): GroupNorm(32, 2048, eps=1e-05, affine=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avg): AdaptiveAvgPool2d(output_size=1)\n",
       "    (conv): Conv2d(2048, 180, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Initialize model\n",
    "model = KNOWN_MODELS[\"BiT-M-R50x1\"](head_size=180, zero_head=True)\n",
    "# Load weights\n",
    "model.load_state_dict(torch.load('siamese/checkpoints/resnetv2_rgb.pth', map_location=device))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after changing relu function: 1.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9960809928151535"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_acc(train_loader, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after changing relu function: 0.97\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9739696312364425"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_acc(valid_loader, model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load model (change activation function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantizeRelu(nn.Module):\n",
    "    def __init__(self, step_size = 0.01):\n",
    "        super().__init__()\n",
    "        self.step_size = step_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        mask = torch.ge(x, 0).bool() # mask for positive values\n",
    "        quantize = torch.ones_like(x) * self.step_size\n",
    "        out = torch.mul(torch.floor(torch.div(x, quantize)), self.step_size) # quantize by step_size\n",
    "        out = torch.mul(out, mask) # zero-out negative values\n",
    "        out = torch.abs(out) # remove sign\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetV2(\n",
       "  (root): Sequential(\n",
       "    (conv): StdConv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (pad): ConstantPad2d(padding=(1, 1, 1, 1), value=0)\n",
       "    (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (body): Sequential(\n",
       "    (block1): Sequential(\n",
       "      (unit01): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (unit02): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit03): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (block2): Sequential(\n",
       "      (unit01): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): StdConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "      (unit02): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit03): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit04): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (block3): Sequential(\n",
       "      (unit01): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): StdConv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "      (unit02): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit03): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit04): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit05): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit06): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (block4): Sequential(\n",
       "      (unit01): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): QuantizeRelu()\n",
       "        (downsample): StdConv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "      (unit02): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 2048, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): QuantizeRelu()\n",
       "      )\n",
       "      (unit03): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 2048, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): QuantizeRelu()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (gn): GroupNorm(32, 2048, eps=1e-05, affine=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avg): AdaptiveAvgPool2d(output_size=1)\n",
       "    (conv): Conv2d(2048, 180, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Initialize model\n",
    "model = KNOWN_MODELS[\"BiT-M-R50x1\"](head_size=180, zero_head=True)\n",
    "# Load weights\n",
    "model.load_state_dict(torch.load('/home/l/liny/ruofan/phishpedia/siamese/checkpoints/resnetv2_rgb.pth', map_location=device))\n",
    "\n",
    "\n",
    "model.body.block4.unit01.relu = QuantizeRelu()\n",
    "model.body.block4.unit02.relu = QuantizeRelu()\n",
    "model.body.block4.unit03.relu = QuantizeRelu()\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compute_acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-05db759b16d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcompute_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'compute_acc' is not defined"
     ]
    }
   ],
   "source": [
    "compute_acc(train_loader, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after changing relu function: 0.97\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9739696312364425"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_acc(valid_loader, model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir('/home/l/liny/ruofan/Network_Signal/')\n",
    "from attack.Attack import *\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "check = adversarial_attack(method='jsma', model=model, dataloader=valid_loader, \n",
    "                           device=device, num_classes=180, save_data=True)\n",
    "acc, _ = check.batch_attack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9739696312364425"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (image, label) in enumerate(valid_loader):\n",
    "    image = image.to(device)\n",
    "    label = label.to(device)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(image, requires_grad=True)\n",
    "output = model(x)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = criterion(output, label)  # loss for ground-truth class\n",
    "\n",
    "model.zero_grad()\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
